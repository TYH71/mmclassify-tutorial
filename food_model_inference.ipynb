{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5caf503",
   "metadata": {
    "id": "e5caf503"
   },
   "source": [
    "# Using a Trained Model to Infer on Images\n",
    "\n",
    "## Environment Setup\n",
    "First, we install prerequisite packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1697b55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1697b55",
    "outputId": "7d7a501e-35df-4f78-e17b-782b12d740e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mmcv\n",
      "  Downloading mmcv-1.3.7.tar.gz (309 kB)\n",
      "\u001b[K     |████████████████████████████████| 309 kB 7.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: addict in /opt/conda/lib/python3.8/site-packages (from mmcv) (2.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from mmcv) (1.19.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.8/site-packages (from mmcv) (8.1.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from mmcv) (5.4.1)\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.8/site-packages (from mmcv) (0.31.0)\n",
      "Building wheels for collected packages: mmcv\n",
      "  Building wheel for mmcv (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mmcv: filename=mmcv-1.3.7-py2.py3-none-any.whl size=447833 sha256=681813e59a223fbc3a6051f0b4930459eb1c33c26a7ea59eecd91b521d86f488\n",
      "  Stored in directory: /root/.cache/pip/wheels/00/73/3f/c28bfe753c596c571cda6889fe11ab6053aa89c8510d099766\n",
      "Successfully built mmcv\n",
      "Installing collected packages: mmcv\n",
      "Successfully installed mmcv-1.3.7\n",
      "fatal: destination path 'mmclassification' already exists and is not an empty directory.\n",
      "Collecting gdown\n",
      "  Downloading gdown-3.13.0.tar.gz (9.3 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from gdown) (4.51.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: requests[socks]>=2.12.0 in /opt/conda/lib/python3.8/site-packages (from gdown) (2.24.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests[socks]>=2.12.0->gdown) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests[socks]>=2.12.0->gdown) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests[socks]>=2.12.0->gdown) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests[socks]>=2.12.0->gdown) (2.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /opt/conda/lib/python3.8/site-packages (from requests[socks]>=2.12.0->gdown) (1.7.1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-3.13.0-py3-none-any.whl size=9034 sha256=7b9ee4d5dc958083f69cb2d42dc807055a8a2c7ead285621c8929e037ff0601c\n",
      "  Stored in directory: /root/.cache/pip/wheels/04/51/53/ed3e97af28b242e9eb81afb4836273fbe233a14228aa82fea3\n",
      "Successfully built gdown\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-3.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mmcv\n",
    "!git clone https://github.com/open-mmlab/mmclassification.git && cd mmclassification && pip install -e .\n",
    "!pip install gdown\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(),'mmclassification'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "jXqeqj9A9xYZ",
   "metadata": {
    "id": "jXqeqj9A9xYZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1E1qD1BJ3NM8Jk1lWWTatdTz2ofkqVp1y\n",
      "To: /home/mmclassify-tutorial/model.pth\n",
      "11.1MB [00:00, 11.4MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model.pth'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "# downloading trained model weights with gdown\n",
    "model_url = 'https://drive.google.com/uc?id=1E1qD1BJ3NM8Jk1lWWTatdTz2ofkqVp1y'\n",
    "local_file = 'model.pth'\n",
    "gdown.download(model_url,local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf06c850",
   "metadata": {
    "id": "bf06c850"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=17UN-0d9xSgHSFL-IAd8hbt7xVpYMc8FH\n",
      "To: /home/mmclassify-tutorial/classes.txt\n",
      "100%|██████████| 1.18k/1.18k [00:00<00:00, 2.87MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'classes.txt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_url = 'https://drive.google.com/uc?id=17UN-0d9xSgHSFL-IAd8hbt7xVpYMc8FH'\n",
    "local_file = 'classes.txt'\n",
    "gdown.download(classes_url,local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524e7429",
   "metadata": {
    "id": "524e7429"
   },
   "source": [
    "## Inference Setup\n",
    "This config file needs to match the same one as the one used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "689ca660",
   "metadata": {
    "id": "689ca660"
   },
   "outputs": [],
   "source": [
    "from mmcv import Config, DictAction\n",
    "cfg = Config.fromfile(\n",
    "    'mmclassification/configs/shufflenet_v2/shufflenet_v2_1x_b64x16_linearlr_bn_nowd_imagenet.py')\n",
    "cfg.model.head.num_classes = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39503bba",
   "metadata": {
    "id": "39503bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmclassify-tutorial/mmclassification/mmcls/apis/inference.py:44: UserWarning: Class names are not saved in the checkpoint's meta data, use imagenet by default.\n",
      "  warnings.warn('Class names are not saved in the checkpoint\\'s '\n"
     ]
    }
   ],
   "source": [
    "from mmcls.apis import init_model, inference_model\n",
    "model = init_model(cfg,'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66ecab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.CLASSES = []\n",
    "with open('classes.txt') as f:\n",
    "    for x in f.readlines():\n",
    "        model.CLASSES.append(x[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e980da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple_pie',\n",
       " 'baby_back_ribs',\n",
       " 'baklava',\n",
       " 'beef_carpaccio',\n",
       " 'beef_tartare',\n",
       " 'beet_salad',\n",
       " 'beignets',\n",
       " 'bibimbap',\n",
       " 'bread_pudding',\n",
       " 'breakfast_burrito',\n",
       " 'bruschetta',\n",
       " 'caesar_salad',\n",
       " 'cannoli',\n",
       " 'caprese_salad',\n",
       " 'carrot_cake',\n",
       " 'ceviche',\n",
       " 'cheesecake',\n",
       " 'cheese_plate',\n",
       " 'chicken_curry',\n",
       " 'chicken_quesadilla',\n",
       " 'chicken_wings',\n",
       " 'chocolate_cake',\n",
       " 'chocolate_mousse',\n",
       " 'churros',\n",
       " 'clam_chowder',\n",
       " 'club_sandwich',\n",
       " 'crab_cakes',\n",
       " 'creme_brulee',\n",
       " 'croque_madame',\n",
       " 'cup_cakes',\n",
       " 'deviled_eggs',\n",
       " 'donuts',\n",
       " 'dumplings',\n",
       " 'edamame',\n",
       " 'eggs_benedict',\n",
       " 'escargots',\n",
       " 'falafel',\n",
       " 'filet_mignon',\n",
       " 'fish_and_chips',\n",
       " 'foie_gras',\n",
       " 'french_fries',\n",
       " 'french_onion_soup',\n",
       " 'french_toast',\n",
       " 'fried_calamari',\n",
       " 'fried_rice',\n",
       " 'frozen_yogurt',\n",
       " 'garlic_bread',\n",
       " 'gnocchi',\n",
       " 'greek_salad',\n",
       " 'grilled_cheese_sandwich',\n",
       " 'grilled_salmon',\n",
       " 'guacamole',\n",
       " 'gyoza',\n",
       " 'hamburger',\n",
       " 'hot_and_sour_soup',\n",
       " 'hot_dog',\n",
       " 'huevos_rancheros',\n",
       " 'hummus',\n",
       " 'ice_cream',\n",
       " 'lasagna',\n",
       " 'lobster_bisque',\n",
       " 'lobster_roll_sandwich',\n",
       " 'macaroni_and_cheese',\n",
       " 'macarons',\n",
       " 'miso_soup',\n",
       " 'mussels',\n",
       " 'nachos',\n",
       " 'omelette',\n",
       " 'onion_rings',\n",
       " 'oysters',\n",
       " 'pad_thai',\n",
       " 'paella',\n",
       " 'pancakes',\n",
       " 'panna_cotta',\n",
       " 'peking_duck',\n",
       " 'pho',\n",
       " 'pizza',\n",
       " 'pork_chop',\n",
       " 'poutine',\n",
       " 'prime_rib',\n",
       " 'pulled_pork_sandwich',\n",
       " 'ramen',\n",
       " 'ravioli',\n",
       " 'red_velvet_cake',\n",
       " 'risotto',\n",
       " 'samosa',\n",
       " 'sashimi',\n",
       " 'scallops',\n",
       " 'seaweed_salad',\n",
       " 'shrimp_and_grits',\n",
       " 'spaghetti_bolognese',\n",
       " 'spaghetti_carbonara',\n",
       " 'spring_rolls',\n",
       " 'steak',\n",
       " 'strawberry_shortcake',\n",
       " 'sushi',\n",
       " 'tacos',\n",
       " 'takoyaki',\n",
       " 'tiramisu',\n",
       " 'tuna_tartare',\n",
       " 'waffles']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cec3fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: ResourceWarning: unclosed <ssl.SSLSocket [closed] fd=75, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "<string>:1: ResourceWarning: unclosed <ssl.SSLSocket [closed] fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "<string>:1: ResourceWarning: unclosed <ssl.SSLSocket [closed] fd=77, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import shutil \n",
    "\n",
    "def download_image(image_url,filename):\n",
    "    r = requests.get(image_url, stream = True)\n",
    "    if r.status_code == 200:\n",
    "        r.raw.decode_content = True\n",
    "        with open(filename,'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "        print('Image sucessfully Downloaded: ',filename)\n",
    "        return True\n",
    "    else:\n",
    "        print('Image Couldn\\'t be retreived')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bab7680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sucessfully Downloaded:  McSpicy.jpg\n",
      "Image sucessfully Downloaded:  ApplePie.jpg\n",
      "Image sucessfully Downloaded:  Salad.jpg\n",
      "Image sucessfully Downloaded:  Mr-Coconut.jpg\n",
      "Image sucessfully Downloaded:  Cheesecake.jpg\n",
      "Image sucessfully Downloaded:  BakChorMee.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_image(\n",
    "    \"https://m.buro247.sg/images/lifestyle/mcspicy-mcds-cra.jpg\",\n",
    "    \"McSpicy.jpg\"\n",
    ")\n",
    "download_image(\n",
    "    \"https://food.fnr.sndimg.com/content/dam/images/food/fullset/2019/7/11/0/FNK_the-best-apple-pie_H_s4x3.jpg.rend.hgtvcom.616.462.suffix/1562853900284.jpeg\",\n",
    "    \"ApplePie.jpg\"\n",
    ")\n",
    "download_image(\n",
    "    \"https://assets.bonappetit.com/photos/5e8cdb60a7a01c00083b08a9/1:1/w_2560%2Cc_limit/HMONG-Potluck-Chopped-Salad.jpg\",\n",
    "    \"Salad.jpg\"\n",
    ")\n",
    "download_image(\n",
    "    \"https://images.happycow.net/venues/1024/11/33/hcmp113353_367000.jpeg\",\n",
    "    \"Mr-Coconut.jpg\"\n",
    ")\n",
    "download_image(\n",
    "    \"https://spanishsabores.com/wp-content/uploads/2020/05/DSC08145.jpg\",\n",
    "    \"Cheesecake.jpg\"\n",
    ")\n",
    "download_image(\n",
    "    \"https://whattocooktoday.com/wp-content/uploads/2016/08/IMG_0414.jpg\",\n",
    "    \"BakChorMee.jpg\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1dd7d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv, matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "images = [\n",
    "    'ApplePie.jpg',\n",
    "    'Salad.jpg',\n",
    "    'McSpicy.jpg',\n",
    "    'Mr-Coconut.jpg',\n",
    "    'Cheesecake.jpg',\n",
    "    'BakChorMee.jpg'\n",
    "]\n",
    "images = []\n",
    "for image_name in images:\n",
    "    img = mmcv.imread(image_name)\n",
    "    images.append(img)\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.imshow(mmcv.bgr2rgb(img))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c5f26e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcls.datasets.pipelines import Compose\n",
    "from mmcv.parallel import collate, scatter\n",
    "import torch\n",
    "import numpy as np\n",
    "def inference_model(model, img):\n",
    "    \"\"\"Inference image(s) with the classifier.\n",
    "    Args:\n",
    "        model (nn.Module): The loaded classifier.\n",
    "        img (str/ndarray): The image filename or loaded image.\n",
    "    Returns:\n",
    "        result (dict): The classification results that contains\n",
    "            `class_name`, `pred_label` and `pred_score`.\n",
    "    \"\"\"\n",
    "    cfg = model.cfg\n",
    "    device = next(model.parameters()).device  # model device\n",
    "    # build the data pipeline\n",
    "    if isinstance(img, str):\n",
    "        if cfg.data.test.pipeline[0]['type'] != 'LoadImageFromFile':\n",
    "            cfg.data.test.pipeline.insert(0, dict(type='LoadImageFromFile'))\n",
    "        data = dict(img_info=dict(filename=img), img_prefix=None)\n",
    "    else:\n",
    "        if cfg.data.test.pipeline[0]['type'] == 'LoadImageFromFile':\n",
    "            cfg.data.test.pipeline.pop(0)\n",
    "        data = dict(img=img)\n",
    "    test_pipeline = Compose(cfg.data.test.pipeline)\n",
    "    data = test_pipeline(data)\n",
    "    data = collate([data], samples_per_gpu=1)\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        # scatter to specified GPU\n",
    "        data = scatter(data, [device])[0]\n",
    "\n",
    "    # forward the model\n",
    "    with torch.no_grad():\n",
    "        scores = model(return_loss=False, **data)\n",
    "        results = []\n",
    "        for i in range(5):\n",
    "            pred_score = np.max(scores, axis=1)[0]\n",
    "            pred_label = np.argmax(scores, axis=1)[0]\n",
    "            result = {'pred_label': pred_label, 'pred_score': float(pred_score)}\n",
    "            result['pred_class'] = model.CLASSES[result['pred_label']]\n",
    "            results.append(result)\n",
    "            scores[0][pred_label] = -999999\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89215b29",
   "metadata": {
    "id": "89215b29"
   },
   "outputs": [],
   "source": [
    "result = inference_model(model,'ApplePie.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6332c707",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6332c707",
    "outputId": "c1cd2ae7-8f19-4e49-b6d8-dd98bc4b6341"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pred_label': 0,\n",
       "  'pred_score': 0.34826740622520447,\n",
       "  'pred_class': 'apple_pie'},\n",
       " {'pred_label': 67,\n",
       "  'pred_score': 0.10955939441919327,\n",
       "  'pred_class': 'omelette'},\n",
       " {'pred_label': 49,\n",
       "  'pred_score': 0.0893409252166748,\n",
       "  'pred_class': 'grilled_cheese_sandwich'},\n",
       " {'pred_label': 19,\n",
       "  'pred_score': 0.07279404997825623,\n",
       "  'pred_class': 'chicken_quesadilla'},\n",
       " {'pred_label': 57,\n",
       "  'pred_score': 0.039468664675951004,\n",
       "  'pred_class': 'hummus'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ffdb6",
   "metadata": {
    "id": "6c2ffdb6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "food_model_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
